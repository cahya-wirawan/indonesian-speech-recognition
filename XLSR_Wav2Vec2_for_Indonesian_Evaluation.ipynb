{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "obvious-dominican",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sysadmin/wirawan/miniconda3/envs/bert2bert/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assumed-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the datasets.\n",
    "# We need to read the audio files as arrays\n",
    "def speech_file_to_array_fn(batch):\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower()\n",
    "    batch[\"sentence\"] = batch[\"sentence\"].replace('！ ', '')\n",
    "    batch[\"sentence\"] = batch[\"sentence\"].replace('，', '')\n",
    "    batch[\"sentence\"] = batch[\"sentence\"].replace('é', 'e')    \n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    resampler = torchaudio.transforms.Resample(sampling_rate, 16_000)\n",
    "    batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "contemporary-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the datasets.\n",
    "# We need to read the aduio files as arrays\n",
    "def evaluate(batch):\n",
    "    inputs = processor(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "directed-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = datasets.load_from_disk(\"sundanese_train_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "banned-jonathan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't find file locally at common_voice/common_voice.py, or remotely at https://raw.githubusercontent.com/huggingface/datasets/1.4.1/datasets/common_voice/common_voice.py.\n",
      "The file was picked from the master branch on github instead at https://raw.githubusercontent.com/huggingface/datasets/master/datasets/common_voice/common_voice.py.\n",
      "Reusing dataset common_voice (/root/.cache/huggingface/datasets/common_voice/id/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    }
   ],
   "source": [
    "test_dataset = load_dataset(\"common_voice\", \"id\", split=\"test\")\n",
    "wer = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "strange-federal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "model_name = \"cahya/wav2vec2-large-xlsr-indonesian-mix\"\n",
    "#model_name = \"./wav2vec2-large-xlsr-indonesian-articial-CV\"\n",
    "#model_name = \"cahya/wav2vec2-large-xlsr-indonesian\"\n",
    "#model_name = \"ayameRushia/wav2vec2-large-xlsr-indonesia-demo\"\n",
    "#model_name = \"Galuh/wav2vec2-large-xlsr-indonesian-demo\"\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name) \n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "appropriate-balance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/common_voice/id/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-6273e8490b649de6.arrow\n"
     ]
    }
   ],
   "source": [
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\'\\”]'\n",
    "test_dataset = test_dataset.map(speech_file_to_array_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "honey-grammar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2858cf1691f64a589fca0ee97f2eb39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=231.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WER: 19.373485\n"
     ]
    }
   ],
   "source": [
    "result = test_dataset.map(evaluate, batched=True, batch_size=8)\n",
    "\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unlike-dispatch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a648f87eb0ef498e961770342c848363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WER: 19.671825\n"
     ]
    }
   ],
   "source": [
    "result = test_dataset.map(evaluate, batched=True, batch_size=64)\n",
    "\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-smith",
   "metadata": {},
   "source": [
    "### Check the sampling rate of the sound files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "nearby-national",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't find file locally at common_voice/common_voice.py, or remotely at https://raw.githubusercontent.com/huggingface/datasets/1.4.1/datasets/common_voice/common_voice.py.\n",
      "The file was picked from the master branch on github instead at https://raw.githubusercontent.com/huggingface/datasets/master/datasets/common_voice/common_voice.py.\n",
      "Reusing dataset common_voice (/root/.cache/huggingface/datasets/common_voice/id/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n",
      "Couldn't find file locally at common_voice/common_voice.py, or remotely at https://raw.githubusercontent.com/huggingface/datasets/1.4.1/datasets/common_voice/common_voice.py.\n",
      "The file was picked from the master branch on github instead at https://raw.githubusercontent.com/huggingface/datasets/master/datasets/common_voice/common_voice.py.\n",
      "Reusing dataset common_voice (/root/.cache/huggingface/datasets/common_voice/id/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"common_voice\", \"id\", split=\"train+validation\")\n",
    "test_dataset = load_dataset(\"common_voice\", \"id\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "according-concept",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['client_id', 'path', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
       "    num_rows: 1844\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "verbal-keeping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accent': '',\n",
       " 'age': '',\n",
       " 'client_id': '057bf45c0c338db897f5717f744bcac8a2ac2eee990a4294ce406f1f79c3326aff181d59e49e7e82813e532ed160c027a80eb4c7e36d8899d3fc96e48d102de5',\n",
       " 'down_votes': 0,\n",
       " 'gender': '',\n",
       " 'locale': 'id',\n",
       " 'path': '/root/.cache/huggingface/datasets/downloads/extracted/fd8a16a97efd77adba3c26c54d0cfae6c9d9494c1017f8070f3f79db72c4b57c/cv-corpus-6.1-2020-12-11/id/clips/common_voice_id_22888800.mp3',\n",
       " 'segment': \"''\",\n",
       " 'sentence': 'Minggu depan kakak perempuan saya menikah.',\n",
       " 'up_votes': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "collaborative-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rates = {}\n",
    "for i, data in enumerate(test_dataset):    \n",
    "    speech_array, sampling_rate = torchaudio.load(data[\"path\"])\n",
    "    if sampling_rate not in sampling_rates:\n",
    "        sampling_rates[sampling_rate] = 1\n",
    "    else:\n",
    "        sampling_rates[sampling_rate] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "civil-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate 48000 1682 91.21475054229936\n",
      "Rate 32000 115 6.236442516268981\n",
      "Rate 44100 44 2.386117136659436\n"
     ]
    }
   ],
   "source": [
    "for rate in sampling_rates:\n",
    "    print(\"Rate\", rate, sampling_rates[rate], sampling_rates[rate]/len(test_dataset)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "impressive-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rates = {}\n",
    "for i, data in enumerate(train_dataset):    \n",
    "    speech_array, sampling_rate = torchaudio.load(data[\"path\"])\n",
    "    if sampling_rate not in sampling_rates:\n",
    "        sampling_rates[sampling_rate] = 1\n",
    "    else:\n",
    "        sampling_rates[sampling_rate] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bored-softball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate 48000 3965 100.0\n"
     ]
    }
   ],
   "source": [
    "for rate in sampling_rates:\n",
    "    print(\"Rate\", rate, sampling_rates[rate], sampling_rates[rate]/len(train_dataset)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "italian-idaho",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3965"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "large-fountain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{48000: 3964}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-madness",
   "metadata": {},
   "source": [
    "### Turkish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "willing-tokyo",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't find file locally at common_voice/common_voice.py, or remotely at https://raw.githubusercontent.com/huggingface/datasets/1.4.1/datasets/common_voice/common_voice.py.\n",
      "The file was picked from the master branch on github instead at https://raw.githubusercontent.com/huggingface/datasets/master/datasets/common_voice/common_voice.py.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset common_voice/tr (download: 592.09 MiB, generated: 2.89 MiB, post-processed: Unknown size, total: 594.98 MiB) to /root/.cache/huggingface/datasets/common_voice/tr/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c50ca6fa5946ca833815652d5c6d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=620848700.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset common_voice downloaded and prepared to /root/.cache/huggingface/datasets/common_voice/tr/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't find file locally at common_voice/common_voice.py, or remotely at https://raw.githubusercontent.com/huggingface/datasets/1.4.1/datasets/common_voice/common_voice.py.\n",
      "The file was picked from the master branch on github instead at https://raw.githubusercontent.com/huggingface/datasets/master/datasets/common_voice/common_voice.py.\n",
      "Reusing dataset common_voice (/root/.cache/huggingface/datasets/common_voice/tr/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"common_voice\", \"tr\", split=\"train+validation\")\n",
    "test_dataset = load_dataset(\"common_voice\", \"tr\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "numeric-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rates = {}\n",
    "for i, data in enumerate(test_dataset):    \n",
    "    speech_array, sampling_rate = torchaudio.load(data[\"path\"])\n",
    "    if sampling_rate not in sampling_rates:\n",
    "        sampling_rates[sampling_rate] = 1\n",
    "    else:\n",
    "        sampling_rates[sampling_rate] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "duplicate-imagination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate 48000 1643 47.23979298447383\n",
      "Rate 44100 4 0.11500862564692352\n"
     ]
    }
   ],
   "source": [
    "for rate in sampling_rates:\n",
    "    print(\"Rate\", rate, sampling_rates[rate], sampling_rates[rate]/len(train_dataset)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "detailed-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rates = {}\n",
    "for i, data in enumerate(train_dataset):    \n",
    "    speech_array, sampling_rate = torchaudio.load(data[\"path\"])\n",
    "    if sampling_rate not in sampling_rates:\n",
    "        sampling_rates[sampling_rate] = 1\n",
    "    else:\n",
    "        sampling_rates[sampling_rate] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "boxed-specific",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate 48000 3462 99.53996549741231\n",
      "Rate 44100 16 0.46003450258769407\n"
     ]
    }
   ],
   "source": [
    "for rate in sampling_rates:\n",
    "    print(\"Rate\", rate, sampling_rates[rate], sampling_rates[rate]/len(train_dataset)*100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
